They  pay  you  enough  for this teaching  faculty. Here. We're  waiting  to  see  the  lecture is  security  of  employment,  right? Cool.  It'd  be  good.  Trailer  bunch  of  those. And  CFC. We  will  get  started. Everyone. So  quick  announcement  before  it  hits  x  over r.  Remember  we  have  a  midterm  coming  up  on  Monday. So  I  released  a  study  guide  last  night. There'll  be  basically  the  same  format, same  presentation  with  last  time. You  can  check  out  the  study  guide with  all  the  details  on  it. I'll  be  updating  it  after  each  lecture. So  sometimes  you  might  imagine  will  appear  there. And  if  you  have  questions  like  that, study  guide  as  concession,  or  you  can  email  me. Right? Okay.  We're  very  pleased  to  welcome. Professor  Charles. Production  control  is  a  professor in  the  Computer  Science  and  Engineering  Department. Also  be  a  former  director  at the  temporal  dynamics  and  Learning  Center  here  at  UCSD. And  he's  the  director  of the  interdisciplinary  PhD  program. I  think  cognitive  science  is particularly  meaningful  for  me because  I  was  formerly  part  of  that  program, was  my  first  introduction  to  the  department. I'd  like  to,  somebody  went  all  the  way over  to  Professor  Charles, going  to  be  talking  about  modeling. Right  over. Thanks  Steve. Yeah,  I'm  a  cognitive  scientist collecting  and  computer  science  salary, which  is  the  right  way  to  do  that. You  don't  want  to  do  it  the  other  way  around. And  my  research  group  has Gary's  unbelievable  research  unit  or  a  guru. We  do  unbelievable  research, which  is  why  we  can't  get  published. Just  kidding.  We  do  get  published. And  my  research  group  members are  neurons  because  the  ion  as  the  unit  and most  sciences  like  the  neuron  and  neuroscience  and the  electron  in  physics  and the  person  and  cognitive  science. So  no  laughs  for  that. Okay,  What  right  over  your  heads. So  your  brain  is  made  up  of  trillions  of  neurons that  are  connected  by  ten  to  the  14th  to  ten  to  the  15th. Connections  between  them. At  the  level  of  synapses, each  cubic  millimeter  of  the  cortex is  about  the  size  of  a  grain  of rice  and  contains  1  billion  synapses. So  each  cell  in  your  brain  only  sees  input from  other  cells  and  it only  sends  electrical  spikes  to  other  cells. So  the  question  is,  how  do  you make  a  mind  out  of  such  a  beast? And  I  think  the  role  of cognitive  science  is  trying  to  figure  that  out. One  of  the  ways  that  we  do  that  is  through  modeling, which  I'll  tell  you  about  in  a  minute. So  there  are  a  lot  of ways  to  figure  out  how  your  brain  works. One  is  measuring  behavior  like  reaction  time. So  if  I  flash some  words  up  on  a  screen  and  you  have  to  say, is  this  a  word  or  not? Then  it  turns  out  your  faster. If  the  word  is  a  frequent  word, your  reaction  time  is  shorter. And  it's  longer  if  it's  infrequent  word. That  tells  you  something  about how  your  brain  responds  to  frequency. You  can  also  measure  brain  waves  with  an  EEG  cap, which  some  people  in  the  Cognitive  Science  Department  do. That  when  your  brain  is  working. There  are  a  lot  of  oscillations, electrical  waves  that  get  generated  by all  this  electrical  activity  between  the  neurons. They  send  electrical  spikes  to  one  another. And  you  can  measure  with an  electrode  cap  waves  at  different  parts  of  the  brain. So  if  I  say,  I  like  my  coffee  with  cream  and  dog. 400  milliseconds  after  the  end  of  the  dog. After  the  beginning  of  dog, you  get  a  big  negative  going  wave that  signals  that  it's  difficult  to integrate  dog  into  that  sentence. So  you  can  tell  stuff  about  how  language  works, and  especially  with  brainwaves and  EEG  caps  when  things  happen. So  it's  got  high  resolution,  high  temporal  resolution. You  can  also  stick  your  head  in a  giant  magnet  who's  had  an  MRI  here? Yeah. So  probably  on  your  knee  but  not  on  your  head,  right. So  you  can  stick  your  head  in  one. I  did  that  yesterday. And  for  his  study  on  Alzheimer's  as  far  as  I  know, I  don't  have  all  centers  yet, but  on  my  way  probably. Anyway. What,  anybody  know  what the  central  atom  of  hemoglobin  is? Hemoglobin. Anybody  you're  shaking  your  head. Yes.  Yeah. Iron?  Yes. So  atoms  have  a  spin. And  if  you  put  a  magnetic  field  on  your  head, all  the  iron  atoms spin  will  start  going  in  one  direction. And  then  you  take the  field  off  and  the  atom  starts  to  precess  like  a  top. And  that  generates  a  signal  that  you  can measure  with  the  head. And  from  that,  you  can  tell. So  it  turns  out  when  your  neurons  fire, they're  sending  little  ions  across  the  channel. They're  not  actually  directly  connected. There's  ions  that  go  between the  output  of  one  neuron  and  the  input  of  another. And  when  it's  done  firing, you  have  to  pump  them  back  out into  the  space  between  the  neurons. And  that  takes  a  lot  of  ATP. And  so  blood  rushes  to  that  spot  to  recharge  the  neurons. And  so  if  you  can  measure  where  the  blood  is, then  you  can  find  out  where your  brain  had  the  most  firing  of  neurons. About  6  s  ago. It  turns  out  with  fMRI, you  can  do  things  like  show  people  pictures  of  faces, show  them  pictures  of  objects, and  you  measure  where  their  brain  is  active. And  you  subtract  one  from  the  other. I  thought  I  actually  saw  that  was  in  another  talk. I  thought  I  saw  a  brain  up  here. Anyway,  if  you  subtract  one  from  the  other, you  get  one  spot  where  it's  more  active  for, actually  get  about  five  spots  where  it's  more  active for  faces,  for  anything  else. And  so  you  can  tell  where  your  brain is  doing  specialized  processing  for  faces, actually  the  fusiform  face  area. But  you  don't  have  very  good  temporal  resolution. So  you  have  good  spatial  resolution. You  know  where  it  is,  but  not  so  well  when  it  was. And  you  can  record  neurons  in the  brains  of  other  animals while  they're  doing  some  task. So  rats,  e.g. we,  have  a  giant  cortex  with  some  hippocampus  with  it. And  rats  more  like  a  giant  hippocampus  with  some  cortex. The  hippocampus  is  where  you remember  things  that  happened  to  you  during  the  day. And  it  has  very  fast  changes in  the  synaptic  strengths  between  neurons. Just  like  I  am  changing  your  brains  right  now, your  synapses  are  changing strength  if  you  remember  anything  I  say  today. And  so  you  can  study  how  memory  works  with  rats,  e.g. and  you  can  record  from  monkeys  and  see  how  vision  works. But  that's  not  a  very  good  way  to study  language  because  monkeys  don't  talk  good. Then  you  can  also record  neurons  in  the  brains of  human  patients  getting  epilepsy, getting  surgery  for  epilepsy. So  if  you  have  intractable  epilepsy, it  can't  be  handled  with  drugs, then  you  might  get  surgery. And  what  they  do  is they  cut  a  hole  in  your  skull  and  they  put  electrodes, electrodes  right  on  the  surface  of  your  brain. And  you  have  to  wear a  giant  turbine  then  to  cover  up  the  hole. And  then  they  take  you off  your  drugs  and  wait  for  you  to  have  a  seizure. So  what  a  seizure  is, is  your  brain  is  a  giant  oscillator. A  lot  of  oscillations  between  the  neurons. That's  kinda  how  they  communicate. But  in  a  seizure, your  whole  brain  gets  entrained  in  one  slow  oscillation. And  so  there's  some  central  pattern  generator somewhere  in  your  brain  that's  causing  that. And  they  wait  for  you  to  have a  seizure  to  find  out  where  it  starts  so they  can  cut  out  the  smallest  part  of your  brain  necessary  to  stop  your  seizures. And  because  you  don't want  to  lose  too  much  of  your  brain, that  thing  you  heard  about  10%  of your  brain  is  what  you  use  is  bullshit. Use  all  of  your  brain  all  the  time, just  some  parts  more  than  others. So  you  don't  want  to  lose  any  because  if you  lose  some  you  will  have  a  deficit. But  that's,  that's  kinda  the,  the  gold  standard. If  you  know  somebody  who  does  that  kind  of surgery  as  they  do  at  UCLA, you  can  while  you're in  the  hospital  for a  few  days  with  these  electrodes  on  your  head. You  can  show  the  subject  pictures and  record  from  their  brains. And  that's  how  they  discovered  the  Halle  Berry  neuron. So  the  Halle  Berry  neuron  is  when  they  recorded from  and  they  showed the  subject  to  these  pictures  of  Halle  Berry. And  these  are  separate  occasions. They  showed  them  the  pictures  and  the  firing  of a  neuron  and  on  different  occasions. And  when  you  sum  those  up, you  get  a  post  histogram  of  where  the, where  the  neurons  fired  the  most. And  this  one  seems  to  like  Halle  Berry. So  the  dots  are  where  the  picture  came  on, the  other  dots  are  where  it  came  off. Even  line  drawings  have  Halle  Berry  even  pictures  of Catwoman  and  even  the  words  Halle  Berry  would. It's  kinda  shocking  how  high  order  this  neuron  is. It  fires  a  little  bit  to  Oprah, not  to  Bill  Clinton. And  it  doesn't  fire  to  Catwoman. But  imagine  how  this  neuron, this  must  be  a  very  high  order  neuron in  response  to  pictures, it  responds  to  text,  line  drawings, even  roles  this  woman  has  played. The  main  idea  of  this  talk  is  that  these  are all  great  ways  of trying  to  understand  how  the  brain  works. But  recording  from  a  neuron  doesn't tell  you  how  that  neuron  got  activated. It  must  have  gotten  activated through  the  visual  word  form  area, through  the  fusiform  face  area,  et  cetera. But  you  don't  know  what  the  computation is  that  cause  that  neuron  to  fire. But  now  we  have  these  computers. We  can  build  models using  neural  networks  that  sweat  drives,  chat, GPT,  that  do  the  same  things  people  do, hopefully  in  a  biologically  plausible  way. And  neural  networks  are  quote-unquote, biologically  plausible. And  then  you  can  take them  apart  in  ways  that  you  can  take apart  people  are  undergraduates and  see  how  they  do  what  they  do. This  the  role  of  cognitive  science, or  sometimes  if  you  want  to  be  fancy  about  it, it's  computational,  cognitive  neuroscience. And  that's  kind  of  what  I  do  on  a  good  day. I  have  three  axioms,  have  cognitive  science. The  first  one  is  the  mind, is  what  the  brain  does. There  is  no  spooky  stuff. We're  not  dualists. If  you  lose  part  of  your  brain, you  will  have  a  deficit  in  your  mind. Um,  and  then  what  the  brain  does  that is  thinking  is  the  kind  of  computation. So  when  you're  walking  across  campus  and  you  see that  person  of  the  appropriate  gender for  your  orientation  and  you  go. That's  a  kind  of  computation. It's  not  a  very  effective  one, leads  to  all  sorts  of  trouble. But  you're  matching  that  person's  face with  some  prototype  you have  in  your  head  of  the  ideal  mate. And  then  the  kind  of  computation  the  brain does  is  inherently  probabilistic. When  I  decided  to  go  home  and  go  to  my  car, I  don't  know  whether  or  not  my  car  will  start. My  battery  might  be  dead. It's  very  unlikely  It's  an  electric  car. But  I  might  have  a  flat  tire. In  the  old  days  of  good  old  fashioned  AI, we  used  to  think  logic  was  the  language  of  thought. And  when  you  did  planning  in  AI, you  had  to  prove  that  your  plan  would  work. So  if  I  plan  to  go  home, I've  got  to  break  it  into sub  steps  and  I  have  to  show  I  can  do  that. But  you'd  have  to  come  up  with  all  sorts  of exceptions  of  what  might  happen like  a  flat  tire  or  somebody  has  stolen your  car  or  it  got  towed,  whatever. But  with  probabilistic  modeling, all  I  have  to  do  is  figure  out the  plan  that's  most  likely  to  work. And  so  it  must  be probabilistic  in  order  to deal  with  the  uncertain  nature  of  the  world. Then. I  think  neural  networks  are  a  good  model of  how  this  kind  of  computation, that's  why  I  use  them. So  what  is  a  working  model? So  here's  12  low-tech  when  it has  a  crank  of  the  visible  B8. I  made  one  of  these  when  I  was  a  kid. It  has  little  spark  plug  lights that  light  up  when  the  piston  go  up  and  down. But  this  won't  actually  drive  your  car,  right? But  with  neural  networks, they  operate  on  computers. Computers  can  be  connected  to hardware  that  can  drive  your  car  and  stuff  like  that. So  actually  a  neural  network  can  drive  your  car. And  so  they're  really  interesting  for  that  reason. And  we  hope  that  they'll  keep  us  as pets  when  they  get  really  smart. So  why  neural  nets? So  the  reason  that you're  still  smarter  than  most  machines, although  maybe  you're  not  smarter  than Chet  GPT  or  GPT  for  at  least. Is  that  Is  it  because we  have  faster  hardware.  Certainly  not. Gpus  are  much  faster  than  the  brain  and  it  takes about  ten  milliseconds  for  a  neuron  to  fire. Whereas  computers  operate  on the  order  of  nanoseconds  or  even  picoseconds? Is  it  because  we  have  better  programs? No,  and  there's  lot  better  programs  can do  things  better  than  we can  multiply  large  numbers  together. And  the  answer  we  think  is  because  it's because  we  have  brains  and  that's  kind  of  a  joke. But  the  idea  is  that brains  are  massively  parallel  machines. Your  neurons  are  all  firing  at some  more  than  others  at different  times  and  there's  trillions  of  them. And  they're  in  some  way  cooperating in  order  to  interpret  the  world and  give  talks  in  COGS  one  and  things  like  that. So  it's  these  basic  differences  in  architecture. This  laptop  here,  it  has the  central  processing  unit  as a  separate  memory  to  do  something. It  has  to  have  an  address  where  something  is  in  memory, go  and  get  that,  pull  it  out, put  it  on  a  workbench  and add  or  subtract  from  it  and  then  put  it  back  in  memory. Our  brains  aren't  like  that. They're,  each  neuron  is  really  just  to  kind  of pattern  detector  for  the  pattern that  it  fires  the  most  two. And  that  pattern  of  connections  between  neurons, that  is  the  synaptic  strengths. What  kind  of  memory  for  a  pattern? So  they're  both  active, their  memory  and  computation  at  the  same  time. So  as  a  result, I  like  to  study  brain  like computational  models  to  try  and  to  understand  them. These  are  actually  very simple  compared  to  the  real  brain. They're  kind  of  cartoon  versions  of  how  the  brain  works. But  because  we  have  computers, we  can  actually  run  these  models  and  see  what  they  do. Then  sometimes  they  surprise  you because  it's  very  hard  to  predict what  a  network  of  neurons  does. These  days. Since  backpropagation  was  rediscovered  here  at UCSD  in  1985  by  Dave  Rumelhart, Geoff  Hinton,  and  Ron  Williams. That  is  the  training  rule that's  still  used  today  in  chat, GPT  and  any  other  neural  network. Except  a  couple  that  Geoff  Hinton  has  come  up  with  since. So  learning  is  a  big  plus. And  what  learning  corresponds  to  in  these  models  is changing  the  connection  strengths  between  the  neurons. And  then  the  steep  learning  stuff that  started  around  2012  or  so, probably  when  you  were  12? Yes.  What  become  a  big  thing  now? And  that's  what  drives  all  of  the, the  modern  AI  stuff  that  we  use. Like  whatever  it  is  that's  translated. Grabbing  my  speech  into text  is  probably  a  deep  neural  network. So  we're  watching  one  at  work  right  now. So  I'm  going  to  talk about  what  human  style  computation  is  like. And  then  I'm  going  to  talk  about  my  favorite  model, the  Interactive  Activation  Model. I'm  not  going  to  talk  about empath  and  don't  have  time  for  that  today. This  is  a  50-minute  class,  right? So  how  did  brains  work? How  do  people  work?  Well,  we're  really  good  at combining  a  lot  of  information  to  understand  English. So  e.g.  if  I  say  the  boy  kissed  the  girl,  it  was  the  boy. We  know  that  in  English  that  means that  the  boy  was  kissing  the  girl, not  the  other  way  round. Whereas  in  Russian,  the  endings  on  those  words, it  could  be  in  this  order  and mean  the  girl  kisses  the  boy. Order  makes  a  big  difference  in  English. Or  is  this  not  going  ahead? But  usually  we  need, so  that's  syntactic  structure  like  subject, verb,  object,  things  like  that. Help  us  understand  English, knowing  stuff  about  that. But  we  also  need  semantics  as  well. So  if  I  say,  I  saw  the  man  on  the  hill  with  the  big  hat, I  saw  the  man  on  the  hill  and  night  telescope. Those  have  identical  parts  pronoun  followed  by  a  verb, followed  by  a  noun  phrase, followed  by  two  prepositional  phrases. But  the  way  that  they  go together  depends  a  lot  on  the  meanings. So  I  saw  the  man  on  the  hill  with  the  big  hat. It's  the  man  hoops. No,  I  don't  have  the  little  arrows  here. So  the  big  hat  modifies  the  man. Whereas  with  my  telescope  modifies. See  how  I  saw  the  man. Unless  he's  running  off  stealing  my  telescope, where  I  have  some  magic  hat  that lets  me  see  things  far  away. So  we  need  meaning  to  be  able  to parse  the  sentence  into the  parts  and  know  what  modifies  what. Ditto  for  pronoun  reference. So  if  I  say  the  city  council  refused the  demonstrators  a  permit  because  they  were  communists. Who  were  they?  So  in  San  Diego, it's  likely  the  demonstrators  that  are  the  communists, whereas  in  Berkeley  It's  probably  the  city  council. And  then  we  do similar  things  with  word  sense  disambiguation. So  this  is  close  to  my  heart  because my  PhD  thesis  was  about  word  sense  disambiguation. The  most  frequent  words  in languages  tend  to  be  the  most  ambiguous. So  goes  a  very  frequent  word has  63  senses  and  the  Merriam  Webster  pocket  dictionary, at  least  when  I  last  looked, take  has  80  some  sentences,  sentences  run. I  counted  over  200  sentence  sentence  senses are  entries  in  the  dictionary  for  the  word  run. But  if  I  say,  I'm  going  for  a  run, you  don  t  think,  Let's  see, is  that  meaning  63  or  meaning  187? No. You  know  immediately  that I'm  going  to  move  my  legs  very  fast. I  don't  ever  run  in  my  stocking or  I'm  not  going  to  buy  or  running my  stocking  and  there's  not  a  run  on the  bank  or  anything  like  that. So  to  do  that, we  need  to  incorporate a  lot  of  different  kinds  of  information. So  discourse  context,  I'm  taking  the  car  means  one  thing. If  you're  a  teenager  talking  to  your  parents, it  means  another  thing. If  you're  sitting  in  the  basement of  the  computer  science  building  programming  and  list, we're  taking  the  car  means  you're grabbing  the  first  element  out  of  the  list. Grammar.  The  carpenter's  saw  the  wood. We  know  from  syntax  that  it's  the  C  kind  of  saw  and not  the  sign  kind  of  saw  because the  past  tense  of  this  kind  of  saw  is  solid. And  so  syntax  tells  us  what  kind  of  saw  that  is  where  n, meaning  frequency  also  helps. So  Bob  threw  a  ball, you  probably  all  thought of  Bob  propelling  a  small  round  thing,  right? You  didn't  think  of  Bob  hosting  a  formal  dance. And  that's  because  that  meaning of  through  is  more  propel, is  more  frequent  than  host  and  ball is  more  frequently  a  small  round  thing  than  a  dance. In  English. Then  there's  associations  between  word  census. So  dogs  bark,  it's  probably the  sound  that  it  makes  and  nut  tree  bark. Although  he  could  my  dog  likes  to pick  up  tree  bark  and  carry  it. Deep,  pit  Deep  could  be  far  down. Or  abstract. Pitt  could  be  a  hole  in  the  ground  or  fruit  seed. And  we  know  that  it's a  far  down  hole  in  the  ground we're  talking  about  and  not  an abstract  fruit  seed  because  of the  way  these  meanings  fit  together. The  man  walked  on  the  deck. World  knowledge. Man  walked  on  the  decades  probably  ship  stack. Now  the  card  deck,  in  this  example  from  Graham  Hearst, Nadia  swung  the  hammered  the  nail  on  the  head  flew  off. We  know  it's  the  hammers  head  and  not  the  nails  head  or nobody  has  had  to  do  to  syntax  and  world  knowledge. But  computers  are  different. They're  fine  with  sentences  like  the  boy, the  girl  that  bought  dog  bit  like  cried. You  probably  don't. At  least  old  style  Natural  Language  Processing  programs. Who  would've  been  fine  with  that? You  probably  don't  think  that's  a  sentence  though. But  you're  probably  okay  with  the  boy  cried. And  you're  probably  even  okay with  the  boy  the  girl  liked  cried. That's  a  reduced  relative. He  took  out  the  boy  that  the  girl  liked,  cried. But  as  soon  as  you  go  one  level  deeper, this  is  called  center  embedding. We  lose  it.  We  can't,  can't  process  that. Computer  science  terms,  it  means our  stack  is  about  two  levels  deep. So  a  computer  can  take  in  a  noun, put  it  on  a  stack, take  the  boy,  the  girl,  the  dog, and  then  verb  comes  along  and  it matches  bit  with  dog  and  pops  off the  stack  and  then  liked  comes  along  and match  that  with  girl  pop  girl  off  the  stack. Cried  comes  along  and  I pop  off  the  stack  and  match  it  with  that  i. So  this  stack  has  three  levels  deep  and  ours  is  two. On  the  other  hand,  right. Through  your  knowledge  of  the  way words  work  in  English  in  California  license  plates, you  can  read  this. But  a  computer  would  have  more  trouble  with  it. Although  these  days  they  can  probably  do  this. So  this  is  audience  participation. I  want  you  to  read  this  aloud  with  me  as  soon  as  I  say it  or  put  it  up  on  the  screen.  Are  you  ready? Set. Go. Thank  you.  Okay.  So  you  said  the  cat. If  you  did  taekwondo  maybe  you  said  Tai  cat, but  this  H  here  and  this  a  here  are  identical. You  disambiguated  in  an  ambiguous  stimulus. Okay? Here's  some  more. I'm  going  to  give  you  for  now. So  in  rapid  succession. So  I  want  you  to  read  each  one  as  I  put  it  up. Ready,  ready. Go. Okay,  very  good. But  here  you  read  this  as  an  R, and  down  here  you  read  it  as  a  p  here, this  is  E  over  here, you  read  it  as  an  f.  Here  you  read  this  as  a  D, and  down  here  you  read  this  as  a  b. So  it's  an  ambiguous  sentence  and  you  said  red. And  the  question  is,  why  didn't  you  say,  okay? Well,  you  can  think  of  a  lot  of  explanations  like,  well, there's  no  verb  in  English  and  this matches  another  word  and  that's  a  reasonable  explanation. But  I  want  to  understand  why  that  happens  in a  model  and  an  implemented  model on  the  computer  that  I  can  run. And  it'll  read  this  word  and  say  read. Okay. Whoops,  I  think. Yeah.  Okay,  So  what  do  you  see  here? It's  a  bunch  of  vegetables,  right? Okay,  now  what  do  you  see? Soldier?  Right?  So  upside  down, face  recognition  is  difficult. Here's  a  picture,  What's  wrong  with  it? Anybody  see  what's  wrong? So  I've  pasted  rocks  face  and the  Michelle's  face  was  hard  to  tell  from  a  distance, but  you  can  see  it  pretty  easily  now  because I  don't  have  Adobe, whatever  it's  called  Illustrator. So  I  did  a  crappy  job. But  context  influences  perception. So  the  context  of  Michelle's  Carolina  in  that  he probably  didn't  notice  that  something's  wrong  with  it. Okay,  how  about  this  one? So  Asian  students  don't  answer  this  question. What's  wrong  with  this  picture? Anybody  notice? Who's  not  Asian? All  the  faces  are  identical. It's  all  the  same  face  in  everyone. If  you're  Chinese  or  Asian  and you're  used  to  individuating  Asians. You'll  notice  that  right  away,  right? Yes. Okay.  So  this  is  an  example  of  something  called the  it's  usually  called  the  other  race  effect. I  prefer  to  call  it  the  unfamiliar  race  effect. So  it's  especially  true  of  white  people. Black  people,  they're  very bad  at  recognizing  black  faces. And  so  this  has  a  lot  of implications  for  eyewitness  testimony. But  if  you're  a  basketball  fan, you  don't  have  this  problem and  you're  used  to  individuating  faces. So  if  you  can  individuate faces  or  then  you're  better  at  this. Okay.  Who's  this?  Adele,  thank  you. How  about  this? Whoops.  That's  called  the  Thatcher  Effect. We're,  we're,  we're  really  bad  at  at  upside  down  faces. So  we  don't  even  notice  that  her  lips  and her  eyes  are  upright  in  this  upside  down  face. But  turn  it  right  side  up. Whoops,  looks  wrong. Okay.  So  that's  called  the  Thatcher  Effect. It  was  invented  by a  British  psychologist  right  after  Margaret  Thatcher, who  was  the  Prime  Minister  of  England, reduced  funding  for  science. So  humans  are  fast  it combining  lots  of  information  to  understand  sentences, to  disambiguate  words,  to  read ambiguous  letters,  to  recognize  faces. And  sometimes  were  such  good  recognizers and  faces  that  we're  used  to  seeing  them right-side-up  and  turning  them  upside  down. Now  messes  us  up. So  neural  nets,  What  do  they  like? And  by  the  way,  feel  free  to  ask  questions  as  we  go. Anybody  has  a  question, the  only  dumb  question  is  the  one  that  wasn't  asked. If  you  have  a  question, probably  several  other  people  have  the  same  question. They're  just  not  brave  enough  to  ask  it. Asking  questions  is  a  really  important  skill for  when  you  go  on  for  your  PhD. So  I  hope  you  all  well, this  is  one  of  the  top  science  universities in  the  United  States, which  means  the  world, which  means  known  space. It's  really  a  good  thing  to  get involved  in  research  while  you're  here. Okay? So  this  is  what  a  real  neuron  looks  like. Ramon  y  Cajal  got  the  Nobel  Prize  for  doing  this. He  was  using  a  new  stained  by, that  was  created  by  Golgi  stain  neurons. And  then  he  looked  in  the  microscope  and  he traced  it  out  and  it  did  this  by  hand. And  they  got  the  Nobel  Prize  at  the  same  time, but  they  hated  each  other, or  at  least  Golgi  hated  can  haul  because Golgi  thought  the  brain  was  one  continuous  web. And  cut  haul  showed  that  there  were discrete  individual  neurons  in  the  brain. So  he  screwed  up  Golgi's  theory. So  here's  a  model  neurons. So  I  didn't  finish  this, so  this  is  input. These  little  bumps  here  are  where  synapses are  connecting  from  other  neurons and  you  can  see  there's  thousands  of  them  here. This  is  cell  body  where  the  electricity  of  the  Selectric spikes  that  happened  between neurons  get  here  and  charge  up  this  neuron. And  if  it  gets  charged  up  enough, it  fires  incentive  spike  out. To  other  neurons. This  actually  isn't  dendrites  the  axon, the  axon  down  here, but  it's  useful  I. So  for  computer  model  that  we imagine  there's  firing  from other  neurons  that  are  the  x's. We  have  some  connection  strengths  we  call  waits. To  see  what  this  neuron  does  is  it takes  this  input  and  multiplies  it  by  the  weight, which  could  be  big  or  small,  positive  or  negative. Multiply  this  times  this  weight,  times  this  weight. And  you  sum  all  that  up. And  you  see  if there's  two  ways  to  then  produce  an  output. You  might  cry  if this  sum  here  crosses  some  threshold  and  fires, that's  a  binary  neuron. Or  you  could  have  a  more smooth  activation  function  depending  on, again,  this  weighted  sum  of  the  inputs. And  that  represents  something  like the  firing  rate  of  the  neuron. So,  if  you  remember your  linear  algebra  and  you  think  about the  x's  here  as  a  vector  and  the  w's  is  a  vector. What's  this  computation  called?  From  high  school? Dot-product,  dot  product  or  inner  product. So  this  tells  you  right  away that  vector  is  just  a  list  of  numbers. But  if  you  plotted, it's  pointing  somewhere  on  a,  on  a  graph. And  the  axes  are  pointing  somewhere. And  when  they  line  up  perfectly, you  get  a  very  strong  response. You  get  a  big  inner  product. If  they're  right  angles,  he  gets  zero. And  if  they're  pointing  in  the  opposite  directions, you  get  the  big  negative  input. And  so  one  thing  about  this, if  I  train  this  thing  to  recognize  me. And  so  say,  show  these  are  pixels,  the  picture  of  me. And  it  doesn't  fire. I  bang  it  on  the  head  and  say  No,  no,  no. And  I  take  my  input  and  add  it  to  the  weights. That's  going  to  make  the  weights  point more  in  the  direction  of  my  face. If  I  give  it  a  picture  of  you  and these  are  all  the  pixels  of  your  face. And  it  fires  a  banging  on  the  head  and  say  No,  no,  no. And  I  subtract  your  pixels  from  the  weights, which  are  going  to  make  the  inputs point  away  from  the  weight  vector. So  in  the  end, if  you've  got  a  weight  for  every  pixel. You  can  plot  these  as  an  image after  I've  turned  it  to  be  a  Gary  detector. And  what  you'll  see  is  a  ghostly  looking  picture of  a  face  because  there's  a  weight  for  every  pixel, I  can  plot  that  as  an  image. And  this  ghostly  looking  face  will  look  like  me, but  it  could  also  be  the  difference between  me  and  all  of  you. And  that's  the  simplest  learning  rule, that's  called  the  perceptron  learning  rule. So  these  are  much  simpler  than  real  neurons. Real  neurons  have  non-linear  interactions. They  have  many  connections  into this  one  thing  and  they  can  build  up  activation. And  there's  nonlinear  interactions  here. It's  just  a  weighted  sum. So  it's  much  simpler  than  a  real  neuron. You  can  spend  a  lot  of supercomputer  time  just  simulating  a  single  neuron. But  by  connecting  these  simple  ones  together  we  can, with  these  weighted  links, we  can  get  an  idea  of how  networks  of  these  neurons  might,  might  work. So  this  is  my  favorite  neural  net  cognitive  model because  it's  the  first  one  I  understood  this  is  from UCSD  and  then  in  1980  it's  called  the Interactive  Activation  Model  of the  effects  of  context  and  letter  perception. And  it's  a  three-layer  network. And  this  was  wired  up  by, it  was  not  trained  in  any  way. It  was  wired  up  to  model,  reading  from  print. And  the  first  layer, that  is  the  feature  level  has  little  bar  detectors. And  we  know  that  the  first  stop  in your  visual  cortex  has  little  barred  detectors  like  that. And  there  are  enough  of  these  to  represent every  letter  in  this  weird  font. And  they're  copied  to  make bar  detectors  for  every  letter  in  a  word. And  so  e.g. this  t  here  has  a  bar along  the  top  and  so  there's  a  bar  here. And  the  vertical  thing  makes  the  rest  of  the T.  And  so  these  features then  excite  letters  that  they're  compatible  with. This  upper  bar  is  compatible  with  an  a, a,  T,  a,  G,  and  N  and  S,  but  not  an  end. And  so  it's  hard  to  see, but  there's  a  little  arrow  here. That  means  it's  a  positive  connection. There's  a  little  round  thing  here that  means  it's  a  negative  connections. So  if  this  is  firing, because  there's  a  bar  in  the  input, it'll  try  and  turn  off  the  end. But  I'll  try  and  turn  on  the  other  four  letters  here. And  then  this  vertical  bar  is  only compatible  with  a  T  because it's  a  vertical  bar  in  the  middle. So  it'll  vote  against  all  of  these  except  for t.  So  t  will  get  two  votes  for  it, a  and  G  and  S  will  get  a  positive  and  a  negative  vote. And  then  these  are  connected  up  by  negative  lengths, so  they're  fighting  it  out there  trying  to  turn  each  other  off. And  the  guy  that  gets  the  most  activation, we'll  turn  off  the  other  units. And  that's  called  a  winner-take-all  network. And  that's  how  one  of  these  things  can  make a  decision  about  what's  in  the  input. Then  there's  four  copies  of  these  for  every  t  in the  first  position  will  have an  identical  one  for  letters  in  the  second  position, third  position,  fourth  position. And  they  encoded  all  four-letter  words in  English  in  this  model, I  don't  know  if  they  included  fucker, not  but  there's  a  couple  of  thousand  of  those. And  so  T  in  the  first  position  here, is  voting  for  all  the  words  that  start  with  T. So  it's  got  a  positive  connection  to trap  trip  taken  time  and  a  negative  connection  to  Abel. And  yeah. So  it,  the,  the  letter  units activate  the  word  units  that  they're  compatible  with. And  as  a  little  quiz  to  make  sure  you're paying  attention  and  not  looking at  your  smartphone  or  your  laptop. Why  does  this  t  vote  against  card? It's  got  a  t  in  it. Yeah. Yeah. This  is  t  in  the  first  position, not  the  fourth  one. So  all  of  these  are  first  position  letters. So  it's  only  voting  for  the  ones  that  start  with  T. But  crucially  in  this  model, the  word  units  that  at  this  level, there's  a  unit  for  every  four-letter  word. They  feed  back  on  the  letters  that  excited  them. Yeah. So  in  the  aging  brain  out  of  these  networks  work, is  that  what  you're  asking? Yeah. Well,  first  you  have  to,  I  mean, this  isn't  learned,  but  first you  have  to  learn  these  networks. And  obviously  this  is  a  toy  model. Your  actual  brain  doesn't  look  like  this, but  as  you  get  older, your  brain  starts  to  shrink  up and  your  brains  are  much  plumper  than  mine. You  have  your  cell  psi or  your  gyri  are  pushing  it  yourself. Cyrus  mine's  kind  of  shrinking  up. And  so  you  lose, you  lose  neurons,  you  lose  white  matter. So  in  general,  all  your  functions  get  a  little  worse. And  if  you  get  Alzheimer's, it  gets  a  lot  worse. And  that  interferes  with communication  between  the  neurons. So  yeah,  I'm  just  on  a  downhill  trend  right  now. Yeah.  Yeah. This,  in  this  model, they're  only  connected  to within  a  layer  or  between  two  layers. But  you  could  imagine  that  this  could  skip this  layer  and  attach  up  here. That's  something  that  we  use  in  modern  neural  networks. It  just  wasn't,  you  know, it's  not  a  necessary  constraint. But  we  do  have  those  in  what  are  called  resonates. Next,  which  G1  you  to  in  your  department  and  bended. Okay,  so  yeah,  but  the  main  point  of  this  model, which  was  from  1980  before backprop  had  been  rediscovered. Rumelhart  and  McClelland  and  the  computers in  the  psychology  department  at  UCSD. They  built  this  model  on  a  computer  and  they  ran  it. And  they  set  all  the  links  here  so that  if  you  had  a  negative  connection  from  one  of  these, it  would  really  turn  off  the  letter. And  so  only  letters  really  compatible  got  excited  here. Then  once  the  word  start  to  get  excited, they  feed  back  on  the  letters  that  excited  them. So  there's  a  t  here. If  there  was  an  RNAi  and  a  p  here, they're  all  voting  for  trip and  trip  votes  back  for  TRIMP. And  that's  how  context  influences  perception  here, the  context  of  this  are  being  in  a, in  a  word  with  p  at  the  end, means  the  p  is  voting  for  trip. Trip  is  voting  for  r.  So there  you  end  up  with  a  stable  coalition  of units  that  are  mutually  exciting one  another  and  that's  what  reaches  your  consciousness. So  this  model,  so  this is  what  it  might  look  like  if  I  turned  on  these  two. And  then  activation  spreads up  here  in  the  T  starts  to  turn  these  guys  off. And  then  it  winds  that  competition. And  now  the  ones  that  start  with  T  or  slightly  active, but  trip  has  four  votes  because  it's TRIMP  triples  only  three  votes. Because  t  and  r  and  p  are  on  these  guys  that  don't, aren't  compatible  at  all  with  the  input  or  off. And  eventually,  you  end  up  with this  stable  coalition  of units  that  are  mutually  supporting  one  another. And  this  accounts  for  the  word  superiority  effect. So  if  I  flash  up  a  word, I've  got  3  min  left,  okay? On  the  screen  at  about  70  milliseconds, that's  less  than  tenth  of  a  second. And  then  a  mask, the  word  and  I  asked  you, was  that  a  i  or  an  a  in  the  third  position? Those  can  both  form  words. You're  better  at  that  and  you  can, I  can  flash  it  faster. And  you're  more  accurate  if  that  r  as in  the  word  trip  or  that  I  is  in  the  word  trip, then  if  I  just  flashed  up  an  eye  on  the  screen  by  itself, that's  called  the  word  superiority  effect. You're  better  at  recognizing  a  letter  in  the  context  of a  word  than  if  it's  in  a  non-word  letters  string  like, I  don't  know,  G,  K, P,  something  like  that. So  let's  do  this  again. Ready,  set,  go. Okay,  so  you  read  this  as  work  in  this  font. This  could  be  an  r  or  a  k. And  this  is  what  happens  in  the  model. When  it  sees  this, you  can  simulate  this  by  only  turning  on those  features  and  not  turning  on  that  feature. And  in  the  third  and  the  fourth  position, this  could  be  a  K  or  it  could  be  an r.  And  this  is  time  going  from  left  to  right. So  they  both  start  out the  same  because  they  have  an  equal  number  of  votes. But  as  soon  as  word  gets  or  work gets  more  active  at  the  word  level  and  word  doesn't. Then  this  feeds  back  on  the  k, giving  the  K  and  the  advantage  over the  r  in  the  fourth  position. Okay,  that  makes  sense. So  this  is  explaining  why. In  this  case  we're  just  cleaning  up  a  noisy  input. But  you  can  see  why  the  feedback  from the  word  level  makes  the  k  more active  than  it  would  have  been  otherwise. Okay,  I'm  going  to  flash  up  a  non-word  letter  string, but  it's  pronounceable,  so  I  want you  to  try  and  pronounce  it  even  though  it's  not  a  word. Ready  Set. Okay? So  in  this  case, there's  actually  a  pseudo  word  superiority  effect. Also. Psychologists,  psycholinguists  make  pseudowords by  taking  real  words and  changing  one  of  the  one  of  the  consonants  usually. So  this  could  have  come  from  year  say. And  the  thing  that  happens  here  is  there's  a  lot  of, it  has  a  lot  of  friends  at  the  word  level. There's  a  lot  of  words  that  end  in  EAD, like  dead  red,  bead  and  head. And  the  four  of  them get  partially  active  because they  don't  start  with  the  why. But  the  four  of  them  are  active  at a  level  such  that  the  amount  of  activation coming  down  from  them  is  as  much  as  there is  for  this  guy  from  one  guy. So  this  is  like  the  Democrats  and  the  Republicans. This  is  got  one  rich  donor  to  vote  for  you. And  here  this  is  like  move  on.org. A  lot  of  small  donors,  like  AOC  gets. So  that's  cool. It  accounts  for  a  lot  of  data  and  it  predicted  new  data. So  splint  is  a  non  pronounceable  non-word, but  it  has  a  lot  of  friends  at  the  word  level  like  slits, flat  slot,  and  the  other  one. And  they  feed  back  on  this  making  S, L  and  T  are  more  active  than  they  would  be  otherwise. And  so  the  model  predicts  that  there  should be  a  superiority  effect  for this  non  pronounceable  non-word  that nobody  would  have  thought  had  a  superiority  effect. And  so  they  tried  it  in  a  bunch  of UCSD  psych  students  and  test  it  out. And  the  prediction  came  true. So  I'm  going  over  its  one-minute  past. Give  me  another  minute  and  I'll  explain why  we  get  read  in  that  job. So  this  is  going  to  excite  RNP  in  the  first  position. This  is  going  to  say  E  and  F  In  the  second, D  and  B  and  the  third. So  we've  got  read  and  public  read  as  three  votes, pub  as  two  votes. There's  no  sub  unit. And  so  in  the  end, what  happens  is  red  wins  out.
